
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../modelling/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.25">
    
    
      
        <title>Model Metrics - Te Whatu Ora AI Learning Resource</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-metrics" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Te Whatu Ora AI Learning Resource" class="md-header__button md-logo" aria-label="Te Whatu Ora AI Learning Resource" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Te Whatu Ora AI Learning Resource
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model Metrics
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Te Whatu Ora AI Learning Resource" class="md-nav__button md-logo" aria-label="Te Whatu Ora AI Learning Resource" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Te Whatu Ora AI Learning Resource
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics_social_license_governance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ethics, Social License & Governance
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../risk_management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Risk Management
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../machine_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../modelling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modelling
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Model Metrics
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Model Metrics
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#regression-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Regression Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regression Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mean-absolute-error-mae" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Error (MAE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-squared-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Squared Error (MSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#root-mean-squared-error-rmse" class="md-nav__link">
    <span class="md-ellipsis">
      Root Mean Squared Error (RMSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-absolute-percentage-error-mape" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Percentage Error (MAPE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#r-squared" class="md-nav__link">
    <span class="md-ellipsis">
      R-Squared
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted-r-squared" class="md-nav__link">
    <span class="md-ellipsis">
      Adjusted R-Squared
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classification-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Classification Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classification Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#four-types-of-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      Four Types of Predictions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      Accuracy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#specificity-true-negative-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Specificity (True Negative Rate)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sensitivity-recall-true-positive-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity (Recall, True Positive Rate)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision" class="md-nav__link">
    <span class="md-ellipsis">
      Precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sensitivity-v-specificity-precision-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity v Specificity &amp; Precision Trade off
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f1-score" class="md-nav__link">
    <span class="md-ellipsis">
      F1 Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#receiver-operating-characteristic-roc-curve" class="md-nav__link">
    <span class="md-ellipsis">
      Receiver Operating Characteristic (ROC) Curve
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#area-under-the-roc-curve-auc-roc" class="md-nav__link">
    <span class="md-ellipsis">
      Area Under the ROC Curve (AUC-ROC)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#regression-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Regression Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regression Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mean-absolute-error-mae" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Error (MAE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-squared-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Squared Error (MSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#root-mean-squared-error-rmse" class="md-nav__link">
    <span class="md-ellipsis">
      Root Mean Squared Error (RMSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-absolute-percentage-error-mape" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Percentage Error (MAPE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#r-squared" class="md-nav__link">
    <span class="md-ellipsis">
      R-Squared
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjusted-r-squared" class="md-nav__link">
    <span class="md-ellipsis">
      Adjusted R-Squared
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classification-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Classification Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classification Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#four-types-of-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      Four Types of Predictions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      Accuracy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#specificity-true-negative-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Specificity (True Negative Rate)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sensitivity-recall-true-positive-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity (Recall, True Positive Rate)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision" class="md-nav__link">
    <span class="md-ellipsis">
      Precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sensitivity-v-specificity-precision-trade-off" class="md-nav__link">
    <span class="md-ellipsis">
      Sensitivity v Specificity &amp; Precision Trade off
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f1-score" class="md-nav__link">
    <span class="md-ellipsis">
      F1 Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#receiver-operating-characteristic-roc-curve" class="md-nav__link">
    <span class="md-ellipsis">
      Receiver Operating Characteristic (ROC) Curve
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#area-under-the-roc-curve-auc-roc" class="md-nav__link">
    <span class="md-ellipsis">
      Area Under the ROC Curve (AUC-ROC)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="model-metrics">Model Metrics</h1>
<p>Model metrics are an extremely important and useful tool when it comes measuring machine learning and AI models. These metrics give us a variety of methods to quantify various aspects of model performance in specific tasks. They enable us to make meaningful comparisons between different types of models so that we can pick the best solution for the job. </p>
<p>In this section we will cover some of the most common performance metrics used in supervised learning for regression and classification tasks. This is by no means exhaustive, but is a solid base of understanding, which should be enough to start reading academic papers that focus on testing the performance of ML/AI models.</p>
<h2 id="regression-metrics">Regression Metrics</h2>
<p><img alt="Regression" src="../images/linear%20_regression.png" /></p>
<p>Regression seeks to gain an optimal result by minimizing an error term. Regression makes its prediction for each instance in a dataset and then compares this to the actual value (target output). The difference between these numbers is the random error for this instance. Regression takes the sum of all errors to quantify how accurate it was across the whole dataset (the smaller the better).</p>
<p>​
A quick definition to know - 'absolute value' is the positive representation of any number (unsigned). This enables negative and positive numbers to be added together without them canceling out so you can preserve the overall size of an effect.</p>
<h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE)</h3>
<p>Measures the average magnitude of prediction errors and is expressed in the same units as the target variable (e.g., mmHg for blood pressure, mg/dL for blood glucose). MAE is less sensitive to outliers compared to other metrics and its interpretability makes it a valuable tool for assessing model performance.​</p>
<h3 id="mean-squared-error-mse">Mean Squared Error (MSE)</h3>
<p>Measures the average squared difference between predicted and actual values. This gives more weight to larger errors to have a disproportionate effect on this metric. If you optimized for MSE, your model would be particularly sensitive to larger errors, as they are weighted more heavily. </p>
<h3 id="root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</h3>
<p>The square-root of the MSE, this converts the MSE back to the units of the target variable making it easier to interpret. While RMSE, similar to MSE, it is sensitive to outliers, but is a balance between MSE and MAE.</p>
<h3 id="mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</h3>
<p>This metric takes each error as a percentage of the observed value. Then it takes the absolute mean of these percentages. This metric's main advantage is being scale agnostic (the units of measurement have no effect on it). This allows comparison of model performance across different datasets and ease of interoperability by stakeholders. To note, it can be undefined or disproportionately high when the actual values are close to zero.</p>
<h3 id="r-squared">R-Squared</h3>
<p>Is a metric used to describe how much of the variance in the target variable is explained by the predictors. It's a value between 0 - 1, where 1 means a perfect  fit, which should always suspicious indicator of overfitting, there is no such thing as a perfect model. We can calculate R-Squared by the following steps:</p>
<ul>
<li>
<p>Total Sum of Squares (TSS): We take the sum, of the square, of each observed value minus its mean. This captures the total variation in the target variable relative to its mean.</p>
</li>
<li>
<p>Residual Sum of Squares (RSS): Nearly the same calculation as TSS but instead, we minus the predicted and observed values from each other. This measures the variation in the target that the model didn't capture.</p>
</li>
</ul>
<p>R-Squared = (TSS-RSS) / TSS</p>
<p>TSS - RSS captures how much variation in the target our model did capture. Then dividing it by TSS converts that to a proportion of total variance (0 - 1) making it agnostic to the units of measurement.
​</p>
<h3 id="adjusted-r-squared">Adjusted R-Squared</h3>
<p>R-Squared does not consider the number of predictors in a model; it only measures the variance explained in the target. Adjusted R-Squared corrects for this by adjusting the R-Squared value based on the number of predictors and the sample size.​</p>
<p>It penalizes the addition of predictors that do not improve the model’s explanatory power. If an added predictor does not increase the explained variance, Adjusted R-Squared will decrease, potentially indicating overfitting. This makes Adjusted R-Squared a more reliable metric for comparing models with different numbers of predictors.​​</p>
<p>It is nearly always preferable to choose the simpler model with fewer predictors if it explains a comparable amount of variance in the target variable as another model with more predictors. This practice helps to reduce the risk of overfitting, lowers computational complexity, and potentially reduces the model's reliance on variables that do not significantly contribute to explaining the variance in the target variable.</p>
<h2 id="classification-metrics">Classification Metrics</h2>
<p>Classification is a type of predictive modeling that aims to assign a label or category to each instance in a dataset. It seeks to determine the most likely class for each instance by analyzing the input features. The performance of a classification model is evaluated by comparing the predicted labels to the actual labels in the dataset.</p>
<h3 id="four-types-of-predictions">Four Types of Predictions</h3>
<p>These are the four types of prediction a classification model can produce:</p>
<p>True Positives (TP) - When the model and reality agree on a positive case.​​</p>
<p>True Negatives (TN) - When the model and reality agree on a negative case.​​</p>
<p>False Positives (FP) - When the model thinks an instance is a positive case, but it's actually negative (Type I error). ​​</p>
<p>False Negatives (FN) - When the model thinks an instance is a negative case, but it's actually positive (Type II error).</p>
<p>The below image is a Confusion Matrix - its is a summary table commonly used to display these four measures in a friendly and convenient way ():</p>
<p><img alt="confusion" src="../images/matrix_class.png" /></p>
<h3 id="accuracy">Accuracy</h3>
<p>Accuracy = (TP + TN) / (TP + TN + FP + FN) </p>
<p>Accuracy is a simple measure that states the proportion of total cases that were correctly classified by the model.​</p>
<p>The inverse of accuracy (1 - accuracy) is called the 'classification error rate'</p>
<h3 id="specificity-true-negative-rate">Specificity (True Negative Rate)</h3>
<p>Specificity = TN / (TN + FP)</p>
<p>Specificity refers to the proportion of individuals without a disease who are correctly identified as negative by a test. This metric is essential when minimizing false positive results is crucial, such as in screening programs where unnecessary follow-up tests or treatments resulting from false alarms can be burdensome and cause undue anxiety for patients.</p>
<h3 id="sensitivity-recall-true-positive-rate">Sensitivity (Recall, True Positive Rate)</h3>
<p>Sensitivity = TP / (TP + FN)</p>
<p>Sensitivity measures the proportion of individuals with a disease who are correctly identified as positive by a test. For instance, if a test has a sensitivity of 0.7 and there are 100 patients with the disease, the test would accurately diagnose 70 of them. High sensitivity is crucial when failing to diagnose a patient with the disease (a false negative) carries severe consequences, even if it means accepting a higher rate of false positives.​</p>
<h3 id="precision">Precision</h3>
<p>Precision = TP / (TP + FP) </p>
<p>Precision refers to the proportion of positive test results that truly represent the presence of the disease. For example, if a test has a precision of 0.85, it means that 85% of patients who test positive actually have the disease. Tests with high precision are crucial when the consequences of a false positive, such as unnecessary treatment or patient anxiety, are significant.​</p>
<h3 id="sensitivity-v-specificity-precision-trade-off">Sensitivity v Specificity &amp; Precision Trade off</h3>
<p>There's often a trade-off between sensitivity (the ability to correctly identify true positives, such as diseased patients) and both precision (the ability to avoid false positives, such as misdiagnosing healthy individuals) and sensitivity (the ability to identify healthy individuals).</p>
<p>When optimizing for higher sensitivity in a model, often leads to decreases in precision and specificity where as the inverse is commonly true when optimizing for precision or specificity.</p>
<p>This balance is especially crucial when dealing with conditions that are rare or have a high cost associated with misdiagnosis. Adjusting diagnostic thresholds or using a two-step approach with different tests can help optimize this balance based on the specific clinical context and the potential consequences of false results. The choice of diagnostic tools and strategies should carefully consider factors such as invasiveness, cost, and the potential impact on patient care.</p>
<h3 id="f1-score">F1 Score</h3>
<p>F1 = 2× ( (Precision * Sensitivity) / (Precision + Sensitivity) )</p>
<p>F1 score is a metric that tries to provide a balanced measure of both recall and precision by using their harmonic mean. Where accuracy is agnostic to class imbalance F1 score is not. Where there is a notable class imbalance this can substantially influence the F1 score, often making it a much more informative metric compared to accuracy. F1 score also does not take true negatives into account which can be important when most cases are negative ones.​</p>
<h3 id="receiver-operating-characteristic-roc-curve">Receiver Operating Characteristic (ROC) Curve</h3>
<p>A graphical representation of a model's ability to distinguish between positive and negative classes. It plots Sensitivity (True Positive Rate) against the False Positive Rate (1 - Specificity).</p>
<p><img alt="Roc" src="../images/roc_curve.jpg" /></p>
<h3 id="area-under-the-roc-curve-auc-roc">Area Under the ROC Curve (AUC-ROC)</h3>
<p>AUC-ROC numerically quantifies what is visually represented by the ROC curve. It takes the area under that curve and ranges from 0 - 1 where 1 is a perfect model. It is important to note that a AUC-ROC of 0.5, is equivalent to picking at random. A score below 0.5 would indicate a model performing worse than picking at random.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.081f42fc.min.js"></script>
      
    
  </body>
</html>